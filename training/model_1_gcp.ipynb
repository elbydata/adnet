{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = np.load(\"../data/array_data_mini/X_train.npz\")[\"arr_0\"]\n",
    "y_train = np.load(\"../data/array_data_mini/y_train.npz\")[\"arr_0\"]\n",
    "X_val = np.load(\"../data/array_data_mini/X_val.npz\")[\"arr_0\"]\n",
    "y_val = np.load(\"../data/array_data_mini/y_val.npz\")[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_size = (X_train[0].shape[0],1)\n",
    "n_classes = 6\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gen_Data(tf.keras.utils.Sequence):\n",
    "    \n",
    "    # generate data batches for model\n",
    "    \n",
    "    def __init__(self,batch_size,seq_size,X_data,y_data):\n",
    "        \n",
    "        # set required attributes\n",
    "        self.batch_size = batch_size\n",
    "        self.t_size = seq_size\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.n_batches = len(self.X_data)//self.batch_size\n",
    "        self.batch_idx = np.array_split(range(len(self.X_data)), self.n_batches)\n",
    "            \n",
    "    def __len__(self):\n",
    "\n",
    "        # set number of batches per epoch\n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        # fetch one batch   \n",
    "        batch_X = self.X_data[self.batch_idx[idx]]\n",
    "        batch_y = self.y_data[self.batch_idx[idx]]\n",
    "        return batch_X, batch_y      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = Gen_Data(batch_size, seq_size, X_train, y_train)\n",
    "val_gen = Gen_Data(batch_size, seq_size, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(seq_size, n_classes):\n",
    "    inputs = tf.keras.Input(shape=seq_size)\n",
    "\n",
    "    # entry block\n",
    "    x = tf.keras.layers.Conv1D(32, 5, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    block_out = x\n",
    "\n",
    "    # 3 downsampling blocks    \n",
    "    for f in [64,128,256]:\n",
    "        \n",
    "        x = tf.keras.layers.Conv1D(f, 5, strides=1, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "        x = tf.keras.layers.Conv1D(f, 5, strides=1, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling1D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        residual = tf.keras.layers.Conv1D(f, 1, strides=2, padding=\"same\")(block_out)\n",
    "        x = tf.keras.layers.add([x, residual])\n",
    "        block_out = x   \n",
    "\n",
    "    # 4 upsampling blocks        \n",
    "    for f in [256, 128, 64, 32]:\n",
    "        \n",
    "        x = tf.keras.layers.Conv1DTranspose(f,5,padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)        \n",
    "        \n",
    "        x = tf.keras.layers.Conv1DTranspose(f,5,padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x) \n",
    "        \n",
    "        x = tf.keras.layers.UpSampling1D(2)(x) \n",
    "                \n",
    "        residual = tf.keras.layers.UpSampling1D(2)(block_out)\n",
    "        residual = tf.keras.layers.Conv1D(f, 1, padding=\"same\")(residual)\n",
    "        x = tf.keras.layers.add([x, residual])\n",
    "        block_out = x      \n",
    "                \n",
    "    # pixel classification layer\n",
    "    outputs = tf.keras.layers.Conv1D(n_classes, 3, activation=\"softmax\", padding=\"same\")(x)    \n",
    "    \n",
    "    # define the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(seq_size,n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(\"unet_trial_1d.h5\",monitor=\"val_loss\",save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"history\", \"wb\") as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar cvfz allfiles.tar.gz *"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
